# -*- coding: utf-8 -*-
"""exam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ruwDmRRlKwLC2Ox30ZwbmPihbI2ln98E
"""

!pip install pdfplumber

import pdfplumber
import re
import json

from google.colab import files
uploaded = files.upload()

def read_pdf(file_name):
    text = ""
    with pdfplumber.open(file_name) as pdf:
        for page in pdf.pages:
            text += page.extract_text() + "\n"
    return text

file_name = list(uploaded.keys())[0]
document_text = read_pdf(file_name)

print(document_text[:1000])  # preview first 1000 chars

def extract_fields(text):
    data = {
        "policy_number": None,
        "date": None,
        "location": None,
        "description": None,
        "estimated_damage": None,
        "claim_type": None
    }

    policy = re.search(r'POLICY NUMBER[:\- ]*(\w+)', text, re.I)
    if policy:
        data["policy_number"] = policy.group(1)

    date = re.search(r'DATE OF LOSS[:\- ]*(\d+/\d+/\d+)', text, re.I)
    if date:
        data["date"] = date.group(1)

    loc = re.search(r'LOCATION OF LOSS[:\- ]*([A-Za-z ,]+)', text, re.I)
    if loc:
        data["location"] = loc.group(1)

    desc = re.search(r'DESCRIPTION OF ACCIDENT[:\- ]*(.*)', text, re.I)
    if desc:
        data["description"] = desc.group(1)

    damage = re.search(r'ESTIMATE AMOUNT[:\- ]*(\d+)', text, re.I)
    if damage:
        data["estimated_damage"] = int(damage.group(1))

    return data

def find_missing_fields(data):
    return [k for k, v in data.items() if v is None]

def route_claim(data, missing):
    if missing:
        return "Manual Review", "Mandatory fields missing"

    if data["description"] and any(w in data["description"].lower()
                                    for w in ["fraud", "staged", "inconsistent"]):
        return "Investigation Flag", "Suspicious keywords found"

    if data["estimated_damage"] and data["estimated_damage"] < 25000:
        return "Fast Track", "Low damage amount"

    return "Standard Processing", "No special rule matched"

def process_claim(text):
    extracted = extract_fields(text)
    missing = find_missing_fields(extracted)
    route, reason = route_claim(extracted, missing)

    result = {
        "extractedFields": extracted,
        "missingFields": missing,
        "recommendedRoute": route,
        "reasoning": reason
    }
    return result

output = process_claim(document_text)
print(json.dumps(output, indent=4))